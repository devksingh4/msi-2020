{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to import data from Google Trends given CSV files and scale them and perform ANOVA (and eventually Tukey HSD) analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import scipy\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I'm going to use pandas to import data from all CSVs that i tell it to import data from into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"EuroHis\", \"ComputerScience\", \"Chemistry\", \"Biology\", \"Physics\", \"Macro\", \"MusicTheory\", \"Statistics\", \"USHis\", \"Psych\"]\n",
    "data = []\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "for name in files: \n",
    "    i = files.index(name)\n",
    "    full_rel_path = \"raw-datasets/\" + name + \".csv\"\n",
    "    data.append(pd.read_csv(full_rel_path, sep=\",\", header=None, skiprows=3)) # First 3 rows have headers that I don't want\n",
    "    data[i] = data[i].drop(data[i].columns[0], axis=1)\n",
    "    data[i] = data[i].replace('<1', '0.1')\n",
    "    data[i].apply(pd.to_numeric)\n",
    "    data[i].columns = ['AP ' + name + ' interest', name + ' interest']\n",
    "    data[i]['AP ' + name + ' interest (scaled)'] = scaler.fit_transform(data[i]['AP ' + name + ' interest'].values.reshape(-1,1))\n",
    "    data[i][name + ' interest (scaled)'] = scaler.fit_transform(data[i][name + ' interest'].values.reshape(-1,1))\n",
    "    data[i] = data[i].drop('AP ' + name + ' interest', 1)\n",
    "    data[i] = data[i].drop(name + ' interest', 1)\n",
    "    dataset = data[i].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above exporting of the scaled dataset is occuring just to backup data in case of failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_stats = []\n",
    "for df in data: \n",
    "    ap_diff = []\n",
    "    field_diff = []\n",
    "    ap_mean = df[df.columns[0]].mean()\n",
    "    field_mean = df[df.columns[1]].mean()\n",
    "    for index, row in df.iterrows(): \n",
    "        ap_interest = row[df.columns[0]]\n",
    "        field_interest = row[df.columns[1]]\n",
    "        ap_diff.append((ap_mean - ap_interest) ** 2) # must be squared because the negative and positive versions cause issues. \n",
    "        field_diff.append((field_mean - field_interest)**2)\n",
    "    dev_stats.append(pd.DataFrame(list(zip(ap_diff, field_diff)),columns =['AP Interest DEV Stat', 'Field DEV Stat']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell takes all of the data processed, calculated the DEV stat, and adds it to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_input = []\n",
    "field_input = []\n",
    "for df in dev_stats:\n",
    "    ap_input.append(np.array(df[df.columns[0]]))\n",
    "    field_input.append(np.array(df[df.columns[1]]))\n",
    "print(scipy.stats.f_oneway(ap_input[0], ap_input[1], ap_input[2], ap_input[3], ap_input[4], ap_input[5], ap_input[6], ap_input[7], ap_input[8]))\n",
    "print(scipy.stats.f_oneway(field_input[0], field_input[1], field_input[2], field_input[3], field_input[4], field_input[5], field_input[6], field_input[7], field_input[8]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This above cell is able to take the data and run ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class PredictionModel(nn.Module):\n",
    "    \"\"\"Dynamically created PredictionModel based off of inputted parameters for layers\"\"\"\n",
    "    def __init__(self, layers):\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        super(PredictionModel, self).__init__()\n",
    "        modules = []\n",
    "        for layer in layers:\n",
    "            modules.append(nn.Linear(layer[0], layer[1]))\n",
    "            modules.append(nn.Tanh())\n",
    "        modules.pop()\n",
    "        self.runModel = nn.Sequential(*modules).to(device)\n",
    "    def forward(self, x):\n",
    "        pred = self.runModel(x)\n",
    "        return pred\n",
    "    def getDevice(self):\n",
    "        return torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from shutil import copyfile\n",
    "import os\n",
    "from livelossplot import PlotLosses \n",
    "# ----------CONFIG---------\n",
    "learning_rate = 1e-4\n",
    "#---------END CONFIG----------\n",
    "model = PredictionModel([[195,150],[150,110],[110,70],[70,30],[30,1]])\n",
    "resuming = False\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "if os.path.isfile('models/interim_model.tar'):\n",
    "    resuming = True\n",
    "    checkpoint = torch.load('models/interim_model.tar')\n",
    "    print(checkpoint.keys())\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss1 = checkpoint['loss']\n",
    "x = torch.tensor(ap_input).to(torch.float).to(model.getDevice())\n",
    "y = torch.tensor(field_input).to(torch.float).to(model.getDevice())\n",
    "liveloss = PlotLosses()\n",
    "for t in range(100):\n",
    "    if resuming:\n",
    "        it = epoch + t\n",
    "        loss = loss1\n",
    "    else: \n",
    "        it = t\n",
    "    print(it)\n",
    "    logs = {}\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if it % 100 == 99:\n",
    "        torch.save({\n",
    "            'epoch': it,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "        }, \"models/interim_model.tar\")\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad\n",
    "    logs['train log loss'] = loss.item()\n",
    "    liveloss.update(logs)\n",
    "    liveloss.draw()\n",
    "    torch.save({\n",
    "        'epoch': it,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, \"models/interim_model.tar\")\n",
    "copyfile(\"models/interim_model.tar\", \"models/final_model.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
